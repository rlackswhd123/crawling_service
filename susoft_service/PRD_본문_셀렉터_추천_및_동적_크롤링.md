# PRD: 본문 셀렉터 추천 및 동적 크롤링 기능

## 1. 개요

크롤링 대상 사이트의 게시글 HTML을 분석하여 본문과 첨부파일의 위치를 자동으로 추천하고, 사용자가 입력한 셀렉터를 기반으로 동적으로 크롤링을 수행하는 기능을 구현합니다.

## 2. 목표

- 새로운 사이트 크롤링 시 본문 위치를 자동으로 추천하여 설정 시간 단축
- 사용자 지정 셀렉터를 사용한 유연한 크롤링 지원
- 첨부파일 크롤링 지원으로 데이터 수집 완성도 향상

## 3. 기능 요구사항

### 3.1 본문 셀렉터 자동 추천 기능

#### 3.1.1 기능 설명
- 게시글 URL 또는 HTML을 입력받아 본문이 위치한 HTML 요소를 자동으로 찾아 추천
- 여러 후보 셀렉터를 신뢰도 점수와 함께 제공
- 첨부파일 위치도 함께 추천

#### 3.1.2 프론트엔드 요구사항
- **ServiceCreateModal 개선**
  - "본문 분석" 버튼 클릭 시 게시글 URL 입력 모달 표시
  - 분석 결과로 추천 셀렉터 목록 표시 (이미 구현된 UI 활용)
  - 각 추천 셀렉터의 미리보기 기능
  - 사용자가 선택한 셀렉터 검증 기능

#### 3.1.3 백엔드 요구사항
- **API 엔드포인트**: `POST /api/crawling/analyze-content`
  - 요청: `{ "url": "게시글 URL", "html": "HTML 내용 (선택)" }`
  - 응답: 추천 셀렉터 목록과 신뢰도 점수
- **분석 알고리즘**
  - HTML 파싱 및 시맨틱 태그 분석 (`<article>`, `<main>`, `<div class="content">` 등)
  - 텍스트 길이 기반 본문 후보 탐색
  - 본문 관련 태그 비율 분석 (`<p>`, `<br>` 등)
  - 광고/네비게이션 패턴 제외 로직
  - 첨부파일 링크 탐색 (파일 확장자, 다운로드 텍스트 등)

### 3.2 사용자 입력 셀렉터 기반 크롤링 기능

#### 3.2.1 기능 설명
- 사용자가 직접 입력한 본문 셀렉터와 첨부파일 셀렉터를 사용하여 크롤링 수행
- 기존 하드코딩된 파서 대신 동적 셀렉터를 지원하는 범용 파서 사용
- 서비스 생성 시 셀렉터 정보를 DB에 저장하고 크롤링 시 활용

#### 3.2.2 프론트엔드 요구사항
- **ServiceCreateModal**
  - 본문 셀렉터 입력 필드 (이미 구현됨)
  - 첨부파일 셀렉터 입력 필드 (이미 구현됨)
  - 서비스 생성 시 셀렉터 정보를 백엔드로 전달
- **CrawlStartModal**
  - 크롤링 시작 시 도메인/서비스의 셀렉터 정보를 백엔드로 전달
  - 또는 백엔드에서 DB에서 자동 조회

#### 3.2.3 백엔드 요구사항
- **범용 파서 모듈 생성**
  - `parsers/generic.py` 생성
  - `parse_detail_generic(html, content_selector, attachment_selector)` 함수 구현
- **기존 파서 수정**
  - 기존 파서들(`gr.py`, `nsulib.py`, `dorm.py`)에 동적 셀렉터 파라미터 추가
  - 기본값은 기존 하드코딩 셀렉터로 설정 (하위 호환성 유지)
- **크롤링 설정 확장**
  - `sites[].content_selector` 필드 추가
  - `sites[].attachment_selector` 필드 추가
  - 크롤링 실행 시 셀렉터 정보 전달

## 4. 데이터 구조

### 4.1 본문 분석 API 요청/응답

**요청:**
```json
{
  "url": "https://example.com/post/123",
  "html": "HTML 내용 (선택사항)"
}
```

**응답:**
```json
{
  "success": true,
  "selectors": {
    "content": {
      "selector": "div.content > p",
      "confidence": 95,
      "candidates": [
        {
          "selector": "div.content > p",
          "confidence": 95,
          "extractedText": "본문 내용 미리보기...",
          "textLength": 1234
        },
        {
          "selector": "article > section",
          "confidence": 80,
          "extractedText": "본문 내용 미리보기...",
          "textLength": 1200
        }
      ]
    },
    "attachment": {
      "selector": "div.view_file a",
      "confidence": 90,
      "candidates": [
        {
          "selector": "div.view_file a",
          "confidence": 90,
          "extractedText": "첨부파일1.pdf",
          "textLength": 0
        }
      ]
    }
  }
}
```

### 4.2 서비스 생성 시 셀렉터 저장

**기존 domains 테이블 활용:**
- `content_selector`: 본문 셀렉터 (이미 존재)
- `attachment_selector`: 첨부파일 셀렉터 (추가 필요할 수 있음)

### 4.3 크롤링 설정 확장

**기존 크롤링 설정에 추가:**
```yaml
sites:
  - id: jeju_go_kr
    content_selector: "div.content > p"  # 사용자 입력 또는 자동 추천
    attachment_selector: "div.view_file a"  # 사용자 입력 또는 자동 추천
    # ... 기존 필드들
```

## 5. 사용자 시나리오

### 시나리오 1: 새 사이트 추가 및 본문 추천 사용
1. 사용자가 "도메인 추가" → "서비스 추가" 클릭
2. 서비스 URL 입력 후 "본문 분석" 버튼 클릭
3. 게시글 URL 입력
4. 시스템이 본문과 첨부파일 셀렉터를 추천하여 표시
5. 사용자가 추천된 셀렉터 중 하나 선택 또는 직접 수정
6. "셀렉터 검증" 버튼으로 정확도 확인
7. 서비스 생성 완료

### 시나리오 2: 사용자 지정 셀렉터로 크롤링
1. 서비스 생성 시 본문/첨부파일 셀렉터 입력
2. 크롤링 시작 모달에서 크롤링 설정 입력
3. 크롤링 실행 시 입력된 셀렉터 사용
4. 크롤링 결과에서 본문과 첨부파일이 올바르게 추출되었는지 확인
5. 문제가 있으면 셀렉터 수정 후 재크롤링

## 6. 기술 요구사항

### 6.1 본문 추천 알고리즘
- HTML 파싱: BeautifulSoup 사용
- 텍스트 길이 기반 후보 탐색
- 시맨틱 태그 우선순위 적용
- 광고/네비게이션 패턴 제외 로직
- 신뢰도 점수 계산 (0-100)

### 6.2 동적 파서 구현
- 범용 파서 모듈 생성
- 기존 파서에 동적 셀렉터 지원 추가
- 셀렉터 검증 로직 (크롤링 전 샘플 URL로 테스트)
- 폴백 메커니즘 (동적 셀렉터 실패 시 기본 셀렉터 시도)

### 6.3 성능 고려사항
- 본문 분석은 비동기 처리 (긴 HTML 분석 시)
- 크롤링 실행은 기존 구조 유지
- 셀렉터 캐싱 (같은 도메인은 재분석 불필요)

## 7. 구현 우선순위

### Phase 1: 본문 추천 기능 (필수)
1. ✅ 백엔드: `POST /api/crawling/analyze-content` API 구현
2. ✅ 백엔드: HTML 분석 알고리즘 구현 (`analyzer.py`)
3. ✅ 프론트엔드: `ServiceCreateModal`의 mock 로직을 실제 API 호출로 교체
4. ✅ 테스트: 다양한 사이트에서 본문 추천 정확도 확인

### Phase 2: 동적 셀렉터 크롤링 (필수)
1. ✅ 백엔드: 범용 파서 모듈 생성 (`parsers/generic.py`)
2. ✅ 백엔드: 기존 파서에 동적 셀렉터 지원 추가
3. ✅ 백엔드: 크롤링 설정에 셀렉터 정보 포함
4. ✅ 프론트엔드: 서비스 생성 시 셀렉터 저장
5. ✅ 프론트엔드: 크롤링 시작 시 셀렉터 전달
6. ✅ 테스트: 사용자 입력 셀렉터로 크롤링 동작 확인

### Phase 3: 개선 사항 (선택)
- 셀렉터 자동 학습 (크롤링 결과 피드백 반영)
- 머신러닝 기반 본문 추천 (향후)
- 셀렉터 히스토리 관리

## 8. 성공 기준

### 8.1 본문 추천 기능
- 다양한 사이트에서 본문 추천 정확도 80% 이상
- 추천 셀렉터 목록에서 올바른 셀렉터가 상위 3개 안에 포함
- 분석 응답 시간 5초 이내

### 8.2 동적 셀렉터 크롤링
- 사용자 입력 셀렉터로 크롤링 성공률 90% 이상
- 기존 하드코딩 파서와 동일한 수준의 데이터 추출 품질
- 첨부파일 크롤링 정확도 85% 이상

## 9. 에러 처리

### 9.1 본문 분석 에러
- HTML 파싱 실패: 에러 메시지 반환
- 본문을 찾을 수 없음: 낮은 신뢰도 셀렉터라도 제공
- 네트워크 에러: 재시도 로직

### 9.2 동적 크롤링 에러
- 셀렉터가 유효하지 않음: 검증 단계에서 에러 반환
- 크롤링 중 셀렉터 실패: 폴백 메커니즘 동작
- 부분 실패: 성공한 데이터는 저장

## 10. 보안 고려사항

- URL 검증 (XSS 방지)
- HTML 크기 제한 (DoS 방지)
- 셀렉터 검증 (악의적 셀렉터 방지)

## 11. 향후 개선사항

- 셀렉터 자동 학습 및 최적화
- 머신러닝 기반 본문 추천
- 크롤링 결과 피드백을 통한 셀렉터 개선
- 셀렉터 버전 관리 및 히스토리

